\chapter*{Abstract}
This thesis summarises the search for a rare process involving the Higgs boson, where the Higgs boson is produced in association with a top quark pair. This analysis was carried out using data from proton-proton collisions in the Large Hadron Collider (LHC), collected by the Compact Muon Solenoid (CMS) detector during the 2016 data taking period. In 2015, the LHC was restarted at an unprecedented centre-of-mass energy of $\sqrt{s}=13$~TeV, significantly increasing the discovery potential of the experiments. The discovery of the top quark pair associated Higgs (\ttH) production process would be a direct confirmation of the standard model (SM) mechanism of mass generation for the most massive known quark. Deviations from the SM expectation would signal the presence of beyond the standard model (BSM) physics affecting the recently-discovered Higgs boson. The \ttH~process has a production cross-section that is about two orders of magnitude below the Higgs production via gluon fusion, which was the channel where this particle was discovered in 2012. Due to the extremely low production rate, all detectable decay modes of the Higgs need to be considered. We concentrated on the dominant decay mode for the Higgs boson, where it decays to bottom quarks which further hadronise to jets. In order to reduce the contribution of multi-jet processes not involving top quarks, we additionally require the presence of charged leptons, which can arise from the leptonic decays of the W bosons from top quark decays. This search, which is made challenging by the presence of an overwhelming background arising from QCD production of \ttbar+jets, necessitated the use of sophisticated particle reconstruction and identification algorithms in the detector. We contributed to the development of a new method for identifying and tagging jets arising from the hadronisation of bottom quarks, which are a feature of both the signal and background processes, by combining information across different detector subsystems using machine learning. This combined b~tagging algorithm improved over the state of the art by reducing the rate of erroneously tagged jets by approximately 10-20\% and was employed in the CMS analysis that saw first evidence for the \Hbb~decay. For the identification of the \ttH~process, we implemented an algorithm that directly uses predictions from quantum field theory via the evaluation of matrix elements to disentangle the signal process from the \ttbar+jets background. We employed this matrix element method in an analysis of CMS data to determine an upper limit on the \ttH~production cross-section at the level of $\mu=\sigma/\sigma_{\mathrm{SM}} < 1.52$ at a 95\% confidence level, with an upper limit of 1.57 expected in the case of no signal. This method is now available to the CMS collaboration and plays a central role in the Run 2 analysis of \ttHbb~in the Higgs group.

Advanced data mining techniques based on artificial intelligence have recently made significant progress on problems in various fields such as vision and translation that were previously thought to be intractable using computers. During an internship at the private company Lingvist, we investigated the use of these adaptive algorithms based on deep learning for a problem where accurate predictions based on theory are not available. We developed an adaptive data-driven method based on neural networks that significantly improved the accuracy of the estimated vocabulary size for people learning a second language. The use of such adaptive techniques based on machine learning shows promise also in the field of natural sciences, in particular in experimental high-energy physics, where the discovery potential can be enhanced by making maximal use of the information recorded by the detector, but also in effectively reducing, filtering and modelling the large amounts of data that are foreseen in the coming decades.